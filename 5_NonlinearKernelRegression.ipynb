{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**WARNING: NOTEBOOK** **IN PROGRESS!!!!!!!!**"
      ],
      "metadata": {
        "id": "OPg1vsNzZjlb"
      },
      "id": "OPg1vsNzZjlb"
    },
    {
      "cell_type": "markdown",
      "id": "f4b1769c-3690-4444-b60e-ad220d2ad5ff",
      "metadata": {
        "id": "f4b1769c-3690-4444-b60e-ad220d2ad5ff"
      },
      "source": [
        "# Install Packages & Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7403b094-8dba-45f6-9be0-15f52109677c",
      "metadata": {
        "id": "7403b094-8dba-45f6-9be0-15f52109677c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy.random import default_rng\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9950d4f-b9fd-4648-b063-3b03712ddb17",
      "metadata": {
        "id": "c9950d4f-b9fd-4648-b063-3b03712ddb17"
      },
      "source": [
        "Import Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b1eef0c4-8a5b-4534-8835-6aef24c1c76d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1eef0c4-8a5b-4534-8835-6aef24c1c76d",
        "outputId": "a39df61f-35fa-4314-ade4-0aab605932a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "path_data = 'data.csv' #edit path as necessary\n",
        "\n",
        "# Check if files exist before loading\n",
        "if os.path.exists(path_data):\n",
        "    data = pd.read_csv(path_data)\n",
        "    print(\"Data loaded successfully.\")\n",
        "else:\n",
        "    print(\"Error: One or both files not found. Check the file paths.\")\n",
        "\n",
        "y = data.loc[:,'ViolentCrimesPerPop']\n",
        "X = data.loc[:, data.columns != 'ViolentCrimesPerPop']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed81b415-378c-46b0-a725-00b4ff64110b",
      "metadata": {
        "id": "ed81b415-378c-46b0-a725-00b4ff64110b"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "38192b2d-c66e-497a-b115-1af884fa3087",
      "metadata": {
        "id": "38192b2d-c66e-497a-b115-1af884fa3087"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "X_standardized = scaler.fit_transform(X) #Standardize X (centered and scaled)\n",
        "colnames = X.columns #Feature names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ba988fac-c24c-4259-8951-48995bebb245",
      "metadata": {
        "id": "ba988fac-c24c-4259-8951-48995bebb245"
      },
      "outputs": [],
      "source": [
        "rng = default_rng(1) #Set a random seed\n",
        "\n",
        "train_prop = 0.6\n",
        "validation_prop = 0.2\n",
        "test_prop = 0.2\n",
        "\n",
        "# Calculate the number of observations for each split\n",
        "total_samples = data.shape[0]\n",
        "train_size = int(train_prop * total_samples)\n",
        "validation_size = int(validation_prop * total_samples)\n",
        "test_size = total_samples - train_size - validation_size\n",
        "\n",
        "# Create a random permutation of row indices\n",
        "indices = rng.choice(np.arange(total_samples), size=(total_samples), replace=False)\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "y_train = y[indices[:train_size]]\n",
        "y_val = y[indices[(train_size + 1):(train_size + validation_size)]]\n",
        "y_test = y[indices[(train_size + validation_size + 1):]]\n",
        "\n",
        "X_train = X_standardized[indices[:train_size]]\n",
        "X_val = X_standardized[indices[(train_size + 1):(train_size + validation_size)]]\n",
        "X_test = X_standardized[indices[(train_size + validation_size + 1):]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A"
      ],
      "metadata": {
        "id": "2KBozq3vNVSn"
      },
      "id": "2KBozq3vNVSn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine validation and train sets into one (we don't need the validation set anymore)."
      ],
      "metadata": {
        "id": "sYpy33h9Yc_a"
      },
      "id": "sYpy33h9Yc_a"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f3241e18-3d88-4202-a0d7-61c1a24f2aa6",
      "metadata": {
        "id": "f3241e18-3d88-4202-a0d7-61c1a24f2aa6"
      },
      "outputs": [],
      "source": [
        "n_folds = 5\n",
        "X_train = np.vstack((X_train, X_val))\n",
        "y_train = np.concatenate((y_train, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to write our code for manual cross validation for Radial Basis Function (RBF) kernel ridge."
      ],
      "metadata": {
        "id": "UbhHonmeYgg4"
      },
      "id": "UbhHonmeYgg4"
    },
    {
      "cell_type": "code",
      "source": [
        "results = {'alpha': [], 'gamma': [], 'avg_mse_cv': [], 'se_mse_cv': []}\n",
        "\n",
        "alpha_values = np.linspace(0.001, 10, 10) #change to make array larger if computation time allows\n",
        "gamma_values = np.linspace(0.001, 10, 10)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "#initialize the parameters\n",
        "best_alpha = None\n",
        "best_gamma = None\n",
        "best_mse = float('inf')\n",
        "\n",
        "# Loop through all combinations of alpha and gamma to determine the best combination\n",
        "for alpha in alpha_values:\n",
        "    for gamma in gamma_values:\n",
        "        model = KernelRidge(alpha=alpha, kernel='rbf', gamma=gamma)\n",
        "        mse_values = []  # To store MSE for each fold\n",
        "\n"
      ],
      "metadata": {
        "id": "-8QXbXkiUil7"
      },
      "id": "-8QXbXkiUil7",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to write our code for manual cross validation for polynomial kernel ridge."
      ],
      "metadata": {
        "id": "nqxrNRizYj5R"
      },
      "id": "nqxrNRizYj5R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B"
      ],
      "metadata": {
        "id": "7CYSrpa0Mx_o"
      },
      "id": "7CYSrpa0Mx_o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare manual CV from part A with sklearn packages."
      ],
      "metadata": {
        "id": "_ZfrNx8zNmRi"
      },
      "id": "_ZfrNx8zNmRi"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}